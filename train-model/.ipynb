{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iporting Dependences\n",
    "import matplotlib\n",
    "!pip install textblob  \n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import os\n",
    "from time import strftime\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up random seed, for reproductability of randomness\n",
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articletext</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44924</th>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44925</th>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44926</th>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44927</th>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44928</th>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             articletext  label\n",
       "44924  BRUSSELS (Reuters) - NATO allies on Tuesday we...      0\n",
       "44925  LONDON (Reuters) - LexisNexis, a provider of l...      0\n",
       "44926  MINSK (Reuters) - In the shadow of disused Sov...      0\n",
       "44927  MOSCOW (Reuters) - Vatican Secretary of State ...      0\n",
       "44928  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df1 = pd.read_csv('df1_clean.csv')\n",
    "df1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                              articletext  label\n",
       "0      Donald Trump just couldn t wish all Americans ...      1\n",
       "1      House Intelligence Committee Chairman Devin Nu...      1\n",
       "2      On Friday, it was revealed that former Milwauk...      1\n",
       "3      On Christmas day, Donald Trump announced that ...      1\n",
       "4      Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                  ...    ...\n",
       "44924  BRUSSELS (Reuters) - NATO allies on Tuesday we...      0\n",
       "44925  LONDON (Reuters) - LexisNexis, a provider of l...      0\n",
       "44926  MINSK (Reuters) - In the shadow of disused Sov...      0\n",
       "44927  MOSCOW (Reuters) - Vatican Secretary of State ...      0\n",
       "44928  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...      0\n",
       "\n",
       "[44929 rows x 2 columns]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[['articletext', 'label']]\n",
    "df1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of empty lines\n",
    "df1 = df1[df1.articletext.isna() == False]\n",
    "length_df1 = len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sublist of original df1, contains # lines picked at random, out of 20671 possible\n",
    "random_indexes = list(np.random.choice(length_df1 - 2, 3000, replace=False))\n",
    "df1 = df1.iloc[random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function dissects text i, attributes polarity scores, positive/negative/neutral, polarity or not, and subject\n",
    "\n",
    "def sentiment_analyzer(dataframe):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    scores = [sid.polarity_scores(i) for i in dataframe.articletext]\n",
    "    compounds = np.array([i['compound'] for i in scores], dtype='float32')\n",
    "    abs_compounds = np.array([np.sqrt(i ** 2) for i in compounds], dtype='float32')\n",
    "    negs = np.array([i['neg'] for i in scores], dtype='float32')\n",
    "    poss = np.array([i['pos'] for i in scores], dtype='float32')\n",
    "    neus = np.array([i['neu'] for i in scores], dtype='float32')\n",
    "    sent = dataframe['articletext'].apply(lambda x: TextBlob(x).sentiment)\n",
    "    pol = np.array([s[0] for s in sent], dtype='float32')\n",
    "    abs_pol = np.array([np.sqrt(i ** 2) for i in pol], dtype='float32')\n",
    "    subj = np.array([s[1] for s in sent], dtype='float32')\n",
    "\n",
    "    return compounds, abs_compounds, negs, poss, neus, sent, pol, abs_pol, subj\n",
    "    compounds, abs_compounds, negs, poss, neus, sent, pol, abs_pol, subj = sentiment_analyzer(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articletext</th>\n",
       "      <th>label</th>\n",
       "      <th>compounds</th>\n",
       "      <th>abs_compounds</th>\n",
       "      <th>negs</th>\n",
       "      <th>neus</th>\n",
       "      <th>poss</th>\n",
       "      <th>pol</th>\n",
       "      <th>abs_pol</th>\n",
       "      <th>subj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>NEW YORK (Reuters) - Financially troubled Puer...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9910</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.062536</td>\n",
       "      <td>0.483074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39427</th>\n",
       "      <td>DUBLIN (Reuters) - The Irish government would ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.123843</td>\n",
       "      <td>0.123843</td>\n",
       "      <td>0.231019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42065</th>\n",
       "      <td>MANCHESTER, England (Reuters) - Prime Minister...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.128083</td>\n",
       "      <td>0.128083</td>\n",
       "      <td>0.259238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35950</th>\n",
       "      <td>ANKARA/ISTANBUL (Reuters) - Turkey criticized ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.323331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20454</th>\n",
       "      <td>What a role model for women and young girls, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.105835</td>\n",
       "      <td>0.105835</td>\n",
       "      <td>0.453447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             articletext  label  compounds  \\\n",
       "34295  NEW YORK (Reuters) - Financially troubled Puer...      0    -0.9910   \n",
       "39427  DUBLIN (Reuters) - The Irish government would ...      0     0.9791   \n",
       "42065  MANCHESTER, England (Reuters) - Prime Minister...      0     0.9459   \n",
       "35950  ANKARA/ISTANBUL (Reuters) - Turkey criticized ...      0     0.9815   \n",
       "20454  What a role model for women and young girls, a...      1     0.9967   \n",
       "\n",
       "       abs_compounds   negs   neus   poss       pol   abs_pol      subj  \n",
       "34295         0.9910  0.133  0.777  0.090  0.062536  0.062536  0.483074  \n",
       "39427         0.9791  0.058  0.742  0.201  0.123843  0.123843  0.231019  \n",
       "42065         0.9459  0.035  0.841  0.124 -0.128083  0.128083  0.259238  \n",
       "35950         0.9815  0.075  0.811  0.114  0.007934  0.007934  0.323331  \n",
       "20454         0.9967  0.043  0.799  0.158  0.105835  0.105835  0.453447  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding columns to df1, matching them with newly created variables\n",
    "compounds, abs_compounds, negs, poss, neus, sent, pol, abs_pol, subj = sentiment_analyzer(df1)\n",
    "\n",
    "df1['compounds'] = compounds\n",
    "df1['abs_compounds'] = abs_compounds\n",
    "df1['negs'] = negs\n",
    "df1['neus'] = neus\n",
    "df1['poss'] = poss\n",
    "df1['pol'] = pol\n",
    "df1['abs_pol'] = abs_pol\n",
    "df1['subj'] = subj\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Logistic Regression ##\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X (predictor) and y (target) variables\n",
    "X = df1[['compounds', 'negs', 'neus', 'poss', 'pol', 'subj']]\n",
    "y = df1['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolboceanunicolai/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# First classifier\n",
    "lrxtrain, lrxtest, lrytrain, lrytest = train_test_split(X, y)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(lrxtrain, lrytrain)\n",
    "lrpreds = lr.predict(lrxtest)\n",
    "accuracy = accuracy_score(lrytest, lrpreds)\n",
    "f1 = f1_score(lrytest, lrpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7013333333333334 0.7083333333333331\n"
     ]
    }
   ],
   "source": [
    "# First attempt gives accuracy and f1 score of (0.7013, 0.7083)\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Improving our classifier using CountVectorizer \n",
    "#####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test Split\n",
    "x_values = df1[['articletext', 'compounds', 'abs_compounds', 'negs', 'neus', 'poss', 'pol', 'abs_pol', 'subj']]\n",
    "y_values = df1['label']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_values, y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans article from numbers, capital letters, punctuation and spaces for better classifier results\n",
    "def clean_article(article):\n",
    "    art = re.sub(\"[^A-Za-z0-9' ]\", '', str(article))\n",
    "    art2 = re.sub(\"[( ' )(' )( ')]\", ' ', str(art))\n",
    "    art3 = re.sub(\"\\s[A-Za-z]\\s\", ' ', str(art2))\n",
    "    return art3.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "model = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=998, max_df=1.0, min_df=1, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2250x998 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 164983 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the vectorizor \n",
    "test_data = model.transform(xtest.articletext)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.DataFrame(training_data.toarray())\n",
    "dftrain.columns = model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = pd.DataFrame(test_data.toarray())\n",
    "dftest.columns = model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolboceanunicolai/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the predictions for y training data\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(dftrain, ytrain)\n",
    "lr2_preds = lr2.predict(dftest)\n",
    "accuracy = accuracy_score(ytest, lr2_preds)\n",
    "f1 = f1_score(ytest, lr2_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984 0.984375\n"
     ]
    }
   ],
   "source": [
    "# Second attempt gives accuracy and f1 score of (0.9893, 0.9843)\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test classifier on real life articles\n",
    "\n",
    "def classify_real_articles():\n",
    "    path = r'Users⁩\\bolboceanunicolai⁩\\Desktop⁩\\fake_news_detector⁩\\⁨articles\\\\'\n",
    "    directory = os.fsencode(path)\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "\n",
    "            article_import = open(path + filename, 'r')\n",
    "\n",
    "            real_article = article_import.read()\n",
    "\n",
    "            # Transformations to fit classifier format\n",
    "            real_article = [real_article]\n",
    "            real_article = model.transform(real_article)\n",
    "            real_article = pd.DataFrame(real_article.toarray())\n",
    "            real_article.columns = model.get_feature_names()\n",
    "\n",
    "            real_article_pred = lr2.predict(real_article)\n",
    "            print(real_article_pred)\n",
    "            if real_article_pred[0] == 0:\n",
    "                print(filename + \" is probably real\")\n",
    "            else:\n",
    "                print(filename + \" is probably fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(lr2, open(\"model.pkl\", \"wb\"), protocol=2)\n",
    "pickle.dump(clean_article, open(\"clean_article.pkl\", 'wb'))\n",
    "pickle.dump(model, open(\"bow2.pkl\", 'wb'), protocol=2)\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
